{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from DataTools import *\n",
    "#from DataTools as dt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembles['adab_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## USE THIS\n",
    "x2, y2 =make_classification(n_samples = 2000, n_features=20, n_redundant=5, n_informative=5,n_repeated=0,\n",
    "                             n_clusters_per_class=2, n_classes=2, random_state=42)\n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split( x2, y2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree=3, gamma=None, kernel='rbf', kernel_params=None,\n",
       "     n_components=100, random_state=42)), ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('adab_c', AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=LogisticRegression(C=1.0, ...    verbose=0, warm_start=False),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'rbf__gamma': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02]), 'rbf__n_components': [25, 50, 100, 250, 500], 'adab_c__base_estimator': [LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, m...ear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)], 'adab_c__learning_rate': [0.1, 0.5, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 = Pipeline( [\n",
    "    ('rbf', Nystroem(kernel= 'rbf', random_state=42)),  ## sigmoid  'poly'\n",
    "    #('fourier',RBFSampler()), \n",
    "     #PolynomialFeatures(degree=4,include_bias=False)),\n",
    "    ('scl', StandardScaler()),\n",
    "    ('adab_c', AdaBoostClassifier( base_estimator = LogisticRegression( n_jobs = -1)))\n",
    "    #('logit', LogisticRegression(n_jobs=-1))\n",
    "])\n",
    "    \n",
    "pipe2_params = {\n",
    "    'rbf__gamma':np.logspace( -2,2,5),\n",
    "    #'rbf__degree':[1,2,3],\n",
    "    'rbf__n_components':[25,50, 100, 250, 500],\n",
    "    #'fourier__gamma':np.logspace( -2,2,5),\n",
    "    #'fourier__n_components':[25,50, 100, 250, 500],\n",
    "    'adab_c__base_estimator':[LogisticRegression( C=c) for c in np.logspace(-2,2,5) ],\n",
    "    'adab_c__learning_rate':[.1, .5, .9]\n",
    "    #'logit__C':np.logspace(-3,3,11),\n",
    "    #'logit_penalty':['l1', 'l2']\n",
    "}\n",
    "\n",
    "pipe2_gs = GridSearchCV( pipe2, pipe2_params, n_jobs =-1)\n",
    "pipe2_gs.fit( x2_train, y2_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.93200000000000005, 0.90600000000000003)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2_gs.score( x2_train, y2_train), pipe2_gs.score( x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/opt/conda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/opt/conda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f79f4213ed0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/conda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f79f4213ed0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/conda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 4, 2, 0, 124054, tzinfo=tzlocal()), 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'session': '3BB6D6A9A1EF4DB6B24A689CA079B79D', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'3BB6D6A9A1EF4DB6B24A689CA079B79D']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 4, 2, 0, 124054, tzinfo=tzlocal()), 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'session': '3BB6D6A9A1EF4DB6B24A689CA079B79D', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'3BB6D6A9A1EF4DB6B24A689CA079B79D'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 4, 2, 0, 124054, tzinfo=tzlocal()), 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'session': '3BB6D6A9A1EF4DB6B24A689CA079B79D', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-19-50262b24edd3>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f79b5d0c9e8, executi..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f79b403cdb0, file \"<ipython-input-19-50262b24edd3>\", line 24>\n        result = <ExecutionResult object at 7f79b5d0c9e8, executi..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f79b403cdb0, file \"<ipython-input-19-50262b24edd3>\", line 24>, result=<ExecutionResult object at 7f79b5d0c9e8, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f79b403cdb0, file \"<ipython-input-19-50262b24edd3>\", line 24>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'Deskew': <class 'DataTools.Deskew'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FactorAnalysis': <class 'sklearn.decomposition.factor_analysis.FactorAnalysis'>, 'FastICA': <class 'sklearn.decomposition.fastica_.FastICA'>, 'GenericUnivariateSelect': <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'Deskew': <class 'DataTools.Deskew'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FactorAnalysis': <class 'sklearn.decomposition.factor_analysis.FactorAnalysis'>, 'FastICA': <class 'sklearn.decomposition.fastica_.FastICA'>, 'GenericUnivariateSelect': <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/home/jovyan/work/Capstone/<ipython-input-19-50262b24edd3> in <module>()\n     19     #'logit__C':np.logspace(-3,3,11),\n     20     #'logit_penalty':['l1', 'l2']\n     21 }\n     22 \n     23 pipe2_gs = GridSearchCV( pipe2, pipe2_params, n_jobs =-1)\n---> 24 pipe2_gs.fit( x2_train, y2_train)\n     25 \n     26 \n     27 \n     28 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, ..., 0, 0, 0]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=0)>\n        X = array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]])\n        y = array([0, 0, 0, ..., 0, 0, 0])\n        groups = None\n        self.param_grid = {'adab_c__base_estimator': [LogisticRegression(C=0.01, class_weight=None, du...ol=0.0001,\n          verbose=0, warm_start=False), LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), LogisticRegression(C=0.10000000000000001, class_...linear', tol=0.0001, verbose=0, warm_start=False), LinearSVC(C=0.10000000000000001, class_weight=No...', random_state=None,\n     tol=0.0001, verbose=0), LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), LinearSVC(C=1.0, class_weight=None, dual=True, f...', random_state=None, tol=0.0001,\n     verbose=0), LogisticRegression(C=10.0, class_weight=None, du...ol=0.0001,\n          verbose=0, warm_start=False), LinearSVC(C=10.0, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), LogisticRegression(C=100.0, class_weight=None, d...ol=0.0001,\n          verbose=0, warm_start=False), LinearSVC(C=100.0, class_weight=None, dual=True,...', random_state=None, tol=0.0001,\n     verbose=0)], 'adab_c__learning_rate': [0.1, 0.5, 0.9], 'rbf__gamma': array([  1.00000000e-02,   1.00000000e-01,   1.0...e+00,\n         1.00000000e+01,   1.00000000e+02]), 'rbf__n_components': [25, 50, 100, 250, 500]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, ..., 0, 0, 0]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Thu Sep 14 04:03:22 2017\nPID: 7810                               Python 3.6.2: /opt/conda/bin/python\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), array([0, 0, 0, ..., 0, 0, 0]), <function _passthrough_scorer>, array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), 0, {'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), array([0, 0, 0, ..., 0, 0, 0]), <function _passthrough_scorer>, array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), 0, {'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), X=array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, ..., 0, 0, 0]), scorer=<function _passthrough_scorer>, train=array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), verbose=0, parameters={'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...rate=0.1, n_estimators=50, random_state=None))])>\n        X_train = array([[ 0.79682467, -2.7641142 , -1.60858525, .... -0.18398866,\n        -1.00801322, -1.33321705]])\n        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), X=array([[ 0.79682467, -2.7641142 , -1.60858525, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=0.1, n_estimators=50, random_state=None)>\n        Xt = array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None), X=array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), sample_weight=None)\n    406         # Check that algorithm is supported\n    407         if self.algorithm not in ('SAMME', 'SAMME.R'):\n    408             raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n    409 \n    410         # Fit\n--> 411         return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n        self.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=0.1, n_estimators=50, random_state=None)>\n        X = array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        sample_weight = None\n    412 \n    413     def _validate_estimator(self):\n    414         \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n    415         super(AdaBoostClassifier, self)._validate_estimator(\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None), X=array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), sample_weight=array([ 0.001001,  0.001001,  0.001001,  0.00100....001001,\n        0.001001,  0.001001,  0.001001]))\n    123                 raise ValueError(\n    124                     \"Attempting to fit with a non-positive \"\n    125                     \"weighted number of samples.\")\n    126 \n    127         # Check parameters\n--> 128         self._validate_estimator()\n        self._validate_estimator = <bound method AdaBoostClassifier._validate_estim...ng_rate=0.1, n_estimators=50, random_state=None)>\n    129 \n    130         # Clear any previous fit results\n    131         self.estimators_ = []\n    132         self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in _validate_estimator(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None))\n    417 \n    418         #  SAMME-R requires predict_proba-enabled base estimators\n    419         if self.algorithm == 'SAMME.R':\n    420             if not hasattr(self.base_estimator_, 'predict_proba'):\n    421                 raise TypeError(\n--> 422                     \"AdaBoostClassifier with algorithm='SAMME.R' requires \"\n    423                     \"that the weak learner supports the calculation of class \"\n    424                     \"probabilities with a predict_proba method.\\n\"\n    425                     \"Please change the base estimator or set \"\n    426                     \"algorithm='SAMME' instead.\")\n\nTypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\nPlease change the base estimator or set algorithm='SAMME' instead.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 238, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 270, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\", line 411, in fit\n    return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\", line 128, in fit\n    self._validate_estimator()\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\", line 422, in _validate_estimator\n    \"AdaBoostClassifier with algorithm='SAMME.R' requires \"\nTypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\nPlease change the base estimator or set algorithm='SAMME' instead.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Thu Sep 14 04:03:22 2017\nPID: 7810                               Python 3.6.2: /opt/conda/bin/python\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), array([0, 0, 0, ..., 0, 0, 0]), <function _passthrough_scorer>, array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), 0, {'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), array([0, 0, 0, ..., 0, 0, 0]), <function _passthrough_scorer>, array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), 0, {'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), X=array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, ..., 0, 0, 0]), scorer=<function _passthrough_scorer>, train=array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), verbose=0, parameters={'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...rate=0.1, n_estimators=50, random_state=None))])>\n        X_train = array([[ 0.79682467, -2.7641142 , -1.60858525, .... -0.18398866,\n        -1.00801322, -1.33321705]])\n        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), X=array([[ 0.79682467, -2.7641142 , -1.60858525, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=0.1, n_estimators=50, random_state=None)>\n        Xt = array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None), X=array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), sample_weight=None)\n    406         # Check that algorithm is supported\n    407         if self.algorithm not in ('SAMME', 'SAMME.R'):\n    408             raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n    409 \n    410         # Fit\n--> 411         return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n        self.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=0.1, n_estimators=50, random_state=None)>\n        X = array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        sample_weight = None\n    412 \n    413     def _validate_estimator(self):\n    414         \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n    415         super(AdaBoostClassifier, self)._validate_estimator(\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None), X=array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), sample_weight=array([ 0.001001,  0.001001,  0.001001,  0.00100....001001,\n        0.001001,  0.001001,  0.001001]))\n    123                 raise ValueError(\n    124                     \"Attempting to fit with a non-positive \"\n    125                     \"weighted number of samples.\")\n    126 \n    127         # Check parameters\n--> 128         self._validate_estimator()\n        self._validate_estimator = <bound method AdaBoostClassifier._validate_estim...ng_rate=0.1, n_estimators=50, random_state=None)>\n    129 \n    130         # Clear any previous fit results\n    131         self.estimators_ = []\n    132         self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in _validate_estimator(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None))\n    417 \n    418         #  SAMME-R requires predict_proba-enabled base estimators\n    419         if self.algorithm == 'SAMME.R':\n    420             if not hasattr(self.base_estimator_, 'predict_proba'):\n    421                 raise TypeError(\n--> 422                     \"AdaBoostClassifier with algorithm='SAMME.R' requires \"\n    423                     \"that the weak learner supports the calculation of class \"\n    424                     \"probabilities with a predict_proba method.\\n\"\n    425                     \"Please change the base estimator or set \"\n    426                     \"algorithm='SAMME' instead.\")\n\nTypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\nPlease change the base estimator or set algorithm='SAMME' instead.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Thu Sep 14 04:03:22 2017\nPID: 7810                               Python 3.6.2: /opt/conda/bin/python\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), array([0, 0, 0, ..., 0, 0, 0]), <function _passthrough_scorer>, array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), 0, {'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), array([0, 0, 0, ..., 0, 0, 0]), <function _passthrough_scorer>, array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), 0, {'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), X=array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, ..., 0, 0, 0]), scorer=<function _passthrough_scorer>, train=array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), verbose=0, parameters={'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...rate=0.1, n_estimators=50, random_state=None))])>\n        X_train = array([[ 0.79682467, -2.7641142 , -1.60858525, .... -0.18398866,\n        -1.00801322, -1.33321705]])\n        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), X=array([[ 0.79682467, -2.7641142 , -1.60858525, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=0.1, n_estimators=50, random_state=None)>\n        Xt = array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None), X=array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), sample_weight=None)\n    406         # Check that algorithm is supported\n    407         if self.algorithm not in ('SAMME', 'SAMME.R'):\n    408             raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n    409 \n    410         # Fit\n--> 411         return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n        self.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=0.1, n_estimators=50, random_state=None)>\n        X = array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        sample_weight = None\n    412 \n    413     def _validate_estimator(self):\n    414         \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n    415         super(AdaBoostClassifier, self)._validate_estimator(\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None), X=array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), sample_weight=array([ 0.001001,  0.001001,  0.001001,  0.00100....001001,\n        0.001001,  0.001001,  0.001001]))\n    123                 raise ValueError(\n    124                     \"Attempting to fit with a non-positive \"\n    125                     \"weighted number of samples.\")\n    126 \n    127         # Check parameters\n--> 128         self._validate_estimator()\n        self._validate_estimator = <bound method AdaBoostClassifier._validate_estim...ng_rate=0.1, n_estimators=50, random_state=None)>\n    129 \n    130         # Clear any previous fit results\n    131         self.estimators_ = []\n    132         self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in _validate_estimator(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None))\n    417 \n    418         #  SAMME-R requires predict_proba-enabled base estimators\n    419         if self.algorithm == 'SAMME.R':\n    420             if not hasattr(self.base_estimator_, 'predict_proba'):\n    421                 raise TypeError(\n--> 422                     \"AdaBoostClassifier with algorithm='SAMME.R' requires \"\n    423                     \"that the weak learner supports the calculation of class \"\n    424                     \"probabilities with a predict_proba method.\\n\"\n    425                     \"Please change the base estimator or set \"\n    426                     \"algorithm='SAMME' instead.\")\n\nTypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\nPlease change the base estimator or set algorithm='SAMME' instead.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-50262b24edd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpipe2_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpipe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe2_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpipe2_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/opt/conda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/opt/conda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f79f4213ed0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/conda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f79f4213ed0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/conda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 4, 2, 0, 124054, tzinfo=tzlocal()), 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'session': '3BB6D6A9A1EF4DB6B24A689CA079B79D', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'3BB6D6A9A1EF4DB6B24A689CA079B79D']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 4, 2, 0, 124054, tzinfo=tzlocal()), 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'session': '3BB6D6A9A1EF4DB6B24A689CA079B79D', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'3BB6D6A9A1EF4DB6B24A689CA079B79D'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 14, 4, 2, 0, 124054, tzinfo=tzlocal()), 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'session': '3BB6D6A9A1EF4DB6B24A689CA079B79D', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '33D386C5925C42798C47AF2F63A303FD', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"pipe2 = Pipeline( [\\n    ('rbf', Nystroem(kernel=...ms, n_jobs =-1)\\npipe2_gs.fit( x2_train, y2_train)\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-19-50262b24edd3>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f79b5d0c9e8, executi..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f79b403cdb0, file \"<ipython-input-19-50262b24edd3>\", line 24>\n        result = <ExecutionResult object at 7f79b5d0c9e8, executi..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f79b403cdb0, file \"<ipython-input-19-50262b24edd3>\", line 24>, result=<ExecutionResult object at 7f79b5d0c9e8, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f79b403cdb0, file \"<ipython-input-19-50262b24edd3>\", line 24>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'Deskew': <class 'DataTools.Deskew'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FactorAnalysis': <class 'sklearn.decomposition.factor_analysis.FactorAnalysis'>, 'FastICA': <class 'sklearn.decomposition.fastica_.FastICA'>, 'GenericUnivariateSelect': <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'Deskew': <class 'DataTools.Deskew'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FactorAnalysis': <class 'sklearn.decomposition.factor_analysis.FactorAnalysis'>, 'FastICA': <class 'sklearn.decomposition.fastica_.FastICA'>, 'GenericUnivariateSelect': <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/home/jovyan/work/Capstone/<ipython-input-19-50262b24edd3> in <module>()\n     19     #'logit__C':np.logspace(-3,3,11),\n     20     #'logit_penalty':['l1', 'l2']\n     21 }\n     22 \n     23 pipe2_gs = GridSearchCV( pipe2, pipe2_params, n_jobs =-1)\n---> 24 pipe2_gs.fit( x2_train, y2_train)\n     25 \n     26 \n     27 \n     28 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, ..., 0, 0, 0]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=0)>\n        X = array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]])\n        y = array([0, 0, 0, ..., 0, 0, 0])\n        groups = None\n        self.param_grid = {'adab_c__base_estimator': [LogisticRegression(C=0.01, class_weight=None, du...ol=0.0001,\n          verbose=0, warm_start=False), LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), LogisticRegression(C=0.10000000000000001, class_...linear', tol=0.0001, verbose=0, warm_start=False), LinearSVC(C=0.10000000000000001, class_weight=No...', random_state=None,\n     tol=0.0001, verbose=0), LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), LinearSVC(C=1.0, class_weight=None, dual=True, f...', random_state=None, tol=0.0001,\n     verbose=0), LogisticRegression(C=10.0, class_weight=None, du...ol=0.0001,\n          verbose=0, warm_start=False), LinearSVC(C=10.0, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), LogisticRegression(C=100.0, class_weight=None, d...ol=0.0001,\n          verbose=0, warm_start=False), LinearSVC(C=100.0, class_weight=None, dual=True,...', random_state=None, tol=0.0001,\n     verbose=0)], 'adab_c__learning_rate': [0.1, 0.5, 0.9], 'rbf__gamma': array([  1.00000000e-02,   1.00000000e-01,   1.0...e+00,\n         1.00000000e+01,   1.00000000e+02]), 'rbf__n_components': [25, 50, 100, 250, 500]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, ..., 0, 0, 0]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Thu Sep 14 04:03:22 2017\nPID: 7810                               Python 3.6.2: /opt/conda/bin/python\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), array([0, 0, 0, ..., 0, 0, 0]), <function _passthrough_scorer>, array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), 0, {'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), array([0, 0, 0, ..., 0, 0, 0]), <function _passthrough_scorer>, array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), 0, {'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), X=array([[-1.15872028, -0.32934678, -1.56664722, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, ..., 0, 0, 0]), scorer=<function _passthrough_scorer>, train=array([ 483,  484,  486,  487,  488,  489,  491,... 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 504,\n       505, 506, 508, 510, 511, 514, 516]), verbose=0, parameters={'adab_c__base_estimator': LinearSVC(C=0.01, class_weight=None, dual=True, ...', random_state=None, tol=0.0001,\n     verbose=0), 'adab_c__learning_rate': 0.1, 'rbf__gamma': 0.01, 'rbf__n_components': 25}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...rate=0.1, n_estimators=50, random_state=None))])>\n        X_train = array([[ 0.79682467, -2.7641142 , -1.60858525, .... -0.18398866,\n        -1.00801322, -1.33321705]])\n        y_train = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('rbf', Nystroem(coef0=1, degree..._rate=0.1, n_estimators=50, random_state=None))]), X=array([[ 0.79682467, -2.7641142 , -1.60858525, .... -0.18398866,\n        -1.00801322, -1.33321705]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=0.1, n_estimators=50, random_state=None)>\n        Xt = array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None), X=array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), sample_weight=None)\n    406         # Check that algorithm is supported\n    407         if self.algorithm not in ('SAMME', 'SAMME.R'):\n    408             raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n    409 \n    410         # Fit\n--> 411         return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n        self.fit = <bound method AdaBoostClassifier.fit of AdaBoost...ng_rate=0.1, n_estimators=50, random_state=None)>\n        X = array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]])\n        y = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n        sample_weight = None\n    412 \n    413     def _validate_estimator(self):\n    414         \"\"\"Check the estimator and set the base_estimator_ attribute.\"\"\"\n    415         super(AdaBoostClassifier, self)._validate_estimator(\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in fit(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None), X=array([[-0.94125797, -0.11015256,  1.43534467, ....  0.3572528 ,\n         0.86411319,  2.2648202 ]]), y=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...0, 1, 0, 1,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0]), sample_weight=array([ 0.001001,  0.001001,  0.001001,  0.00100....001001,\n        0.001001,  0.001001,  0.001001]))\n    123                 raise ValueError(\n    124                     \"Attempting to fit with a non-positive \"\n    125                     \"weighted number of samples.\")\n    126 \n    127         # Check parameters\n--> 128         self._validate_estimator()\n        self._validate_estimator = <bound method AdaBoostClassifier._validate_estim...ng_rate=0.1, n_estimators=50, random_state=None)>\n    129 \n    130         # Clear any previous fit results\n    131         self.estimators_ = []\n    132         self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py in _validate_estimator(self=AdaBoostClassifier(algorithm='SAMME.R',\n        ...ing_rate=0.1, n_estimators=50, random_state=None))\n    417 \n    418         #  SAMME-R requires predict_proba-enabled base estimators\n    419         if self.algorithm == 'SAMME.R':\n    420             if not hasattr(self.base_estimator_, 'predict_proba'):\n    421                 raise TypeError(\n--> 422                     \"AdaBoostClassifier with algorithm='SAMME.R' requires \"\n    423                     \"that the weak learner supports the calculation of class \"\n    424                     \"probabilities with a predict_proba method.\\n\"\n    425                     \"Please change the base estimator or set \"\n    426                     \"algorithm='SAMME' instead.\")\n\nTypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\nPlease change the base estimator or set algorithm='SAMME' instead.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline( [\n",
    "    ('rbf', Nystroem(kernel= 'rbf', random_state=42)),  ## sigmoid  'poly'\n",
    "    #('fourier',RBFSampler()), \n",
    "     #PolynomialFeatures(degree=4,include_bias=False)),\n",
    "    ('scl', StandardScaler()),\n",
    "    ('adab_c', AdaBoostClassifier( base_estimator = LogisticRegression( n_jobs = -1)))\n",
    "    #('logit', LogisticRegression(n_jobs=-1))\n",
    "])\n",
    "    \n",
    "pipe2_params = {\n",
    "    'rbf__gamma':np.logspace( -2,2,5),\n",
    "    #'rbf__degree':[1,2,3],\n",
    "    'rbf__n_components':[25,50, 100, 250, 500],\n",
    "    #'fourier__gamma':np.logspace( -2,2,5),\n",
    "    #'fourier__n_components':[25,50, 100, 250, 500],\n",
    "    #'adab_c__base_estimator':[LogisticRegression( C=c) for c in np.logspace(-2,2,5) ],\n",
    "    'adab_c__base_estimator':[est.set_params( C=c) for c in np.logspace(-2,2,5) for est in [LogisticRegression(), LinearSVC() ]], # \n",
    "    'adab_c__learning_rate':[.1, .5, .9]\n",
    "    #'logit__C':np.logspace(-3,3,11),\n",
    "    #'logit_penalty':['l1', 'l2']\n",
    "}\n",
    "\n",
    "pipe2_gs = GridSearchCV( pipe2, pipe2_params, n_jobs =-1)\n",
    "pipe2_gs.fit( x2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " LinearSVC(C=0.10000000000000001, class_weight=None, dual=True,\n",
       "      fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "      max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
       "      tol=0.0001, verbose=0),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LinearSVC(C=10.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LinearSVC(C=100.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[est.set_params( C=c) for c in np.logspace(-2,2,5) for est in [LogisticRegression(), LinearSVC()]] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit.set_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
